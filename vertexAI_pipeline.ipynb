{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41caae9e",
   "metadata": {},
   "source": [
    "USING VERTEX AI MODEL FOR EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d00ad451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Dict\n",
    "from sklearn.cluster import KMeans\n",
    "from db_connections.pg_sql import session, Ticket\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a73c5712",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"decent-era-442806-n3\"\n",
    "LOCATION = \"us-central1\"  # Your Vertex AI region\n",
    "EMBEDDING_DIM = 768\n",
    "N_CLUSTERS = 2\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"D:/codes/langGraph_venv/embedding_POC/credentials.json\"\n",
    "os.environ[\"INCIDENTS_CSV_PATH\"] = \"D:/codes/langGraph_venv/embedding_POC/mock_incidents_100.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e66394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528e43e3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ce479192",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tickets = [\n",
    "    {\"ticket_id\": \"1\", \"text\": \"Cannot connect to the company VPN, it keeps saying authentication failed.\", \"category\": \"Network\"},\n",
    "    {\"ticket_id\": \"2\", \"text\": \"My Microsoft Outlook is not opening, it crashes on startup.\", \"category\": \"Software\"},\n",
    "    {\"ticket_id\": \"3\", \"text\": \"The new laptop I received won't boot up, it shows a black screen.\", \"category\": \"Hardware\"},\n",
    "    {\"ticket_id\": \"4\", \"text\": \"I'm unable to access the shared drive, it says permission denied.\", \"category\": \"Network\"},\n",
    "    {\"ticket_id\": \"5\", \"text\": \"Excel is freezing frequently when I work with large spreadsheets.\", \"category\": \"Software\"},\n",
    "    {\"ticket_id\": \"6\", \"text\": \"The printer on the 3rd floor is not working, documents are stuck in queue.\", \"category\": \"Hardware\"},\n",
    "    {\"ticket_id\": \"7\", \"text\": \"How do I reset my domain password?\", \"category\": \"Account\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8efbf911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data processing with psycopg2...\n",
      "Loading incidents from CSV: D:/codes/langGraph_venv/embedding_POC/mock_incidents_100.csv...\n",
      "Loaded 100 incidents from CSV.\n",
      "First 5 rows of loaded data:\n",
      "  ticket_id                                               text  \\\n",
      "0  INC-1000  Troubleshooting Network connectivity issue. Ro...   \n",
      "1  INC-1001  Investigating Network connectivity issue. Affe...   \n",
      "2  INC-1002  Urgent: API endpoint timeout impacts ERP avail...   \n",
      "3  INC-1003  Investigating Server CPU spike. Affecting HR u...   \n",
      "4  INC-1004  Urgent: Printer not responding impacts ERP ava...   \n",
      "\n",
      "                   created_at                  updated_at    status priority  \n",
      "0  2024-06-12 06:56:43.002475  2024-06-12 14:56:43.002475  Resolved   Medium  \n",
      "1  2025-02-13 22:56:43.002475  2025-02-15 02:56:43.002475      Open   Medium  \n",
      "2  2024-11-26 12:56:43.002475  2024-11-27 18:56:43.002475    Closed      Low  \n",
      "3  2024-08-18 15:56:43.002475  2024-08-19 07:56:43.002475      Open   Medium  \n",
      "4  2025-03-17 04:56:43.002475  2025-03-17 22:56:43.002475      Open     High  \n"
     ]
    }
   ],
   "source": [
    "print(\"Starting data processing with psycopg2...\")\n",
    "\n",
    "# 1. Fetch Mock Incidents\n",
    "\n",
    "INCIDENTS_CSV_PATH = os.getenv(\"INCIDENTS_CSV_PATH\")\n",
    "print(f\"Loading incidents from CSV: {INCIDENTS_CSV_PATH}...\")\n",
    "\n",
    "try:\n",
    "    # pd.read_csv automatically infers types, but we explicitly parse dates\n",
    "    incidents_df = pd.read_csv(\n",
    "        INCIDENTS_CSV_PATH,\n",
    "        parse_dates=['created_at', 'updated_at'], # Parse these columns as datetime objects\n",
    "        dayfirst=True # Adjust based on your date format (e.g., True for DD/MM/YYYY)\n",
    "    )\n",
    "    print(f\"Loaded {len(incidents_df)} incidents from CSV.\")\n",
    "    print(\"First 5 rows of loaded data:\")\n",
    "    print(incidents_df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: CSV file not found at {INCIDENTS_CSV_PATH}. Please check your .env file path.\")\n",
    "    exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV: {e}\")\n",
    "    exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d39477d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertex_embedding(texts: List[str]) -> List[List[float]]:\n",
    "    \"\"\"Generate embeddings \n",
    "    using Vertex AI Gecko model.\"\"\"\n",
    "    embedding_model = TextEmbeddingModel.from_pretrained(\"text-embedding-004\")\n",
    "    embeddings = embedding_model.get_embeddings(texts)\n",
    "    # embeddings is a list of Embedding objects; extract embedding vector\n",
    "    return [emb.values for emb in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa54f8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INC-1000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "284fa985",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_and_store_to_pgvector(kmeans: KMeans, tickets: List[Dict[str, Any]] | None =None, tickets_df:pd.DataFrame | None = None ):\n",
    "    if tickets: \n",
    "        texts = [ticket['text'] for ticket in tickets]\n",
    "    if tickets_df is not None:\n",
    "        texts = tickets_df['text'].tolist()\n",
    "    print(\"Generating\")\n",
    "    embeddings = get_vertex_embedding(texts)\n",
    "    print(f\"generated embedding for {len(embeddings)} ticketsa\")\n",
    "    cluster_ids = kmeans.fit_predict(embeddings)\n",
    "    print(\"Kmeans cluster ids\", cluster_ids)\n",
    "    session.rollback()\n",
    "    if tickets:\n",
    "        for i, ticket in enumerate(tickets):\n",
    "            embedding = np.array(embeddings[i], dtype=np.float32)\n",
    "            new_ticket = Ticket(\n",
    "                ticket_id=ticket['ticket_id'],\n",
    "                text=ticket['text'],\n",
    "                embedding=embedding,\n",
    "                cluster_id=int(cluster_ids[i])\n",
    "            )\n",
    "            session.add(new_ticket)\n",
    "        print(f\"Inserted {len(tickets)} tickets into PostgreSQL with pgvector.\")\n",
    "    if tickets_df is not None:\n",
    "        for i, row in tickets_df.iterrows():\n",
    "            embedding = np.array(embeddings[i], dtype=np.float32)\n",
    "            new_ticket = Ticket(\n",
    "                ticket_id=row['ticket_id'],\n",
    "                text=row['text'],\n",
    "                embedding=embedding,\n",
    "                cluster_id=int(cluster_ids[i])\n",
    "            )\n",
    "            session.add(new_ticket)\n",
    "        print(f\"Inserted {len(incidents_df)} tickets into PostgreSQL with pgvector.\")\n",
    "\n",
    "\n",
    "    session.commit()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "97bada02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sqlalchemy import text\n",
    "# session.rollback() \n",
    "# # sql = text(\"\"\"\n",
    "# #        SELECT id, ticket_id, text,\n",
    "# #                embedding <-> (:query_embedding)::vector AS distance\n",
    "# #         FROM tickets\n",
    "# #         ORDER BY embedding <-> (:query_embedding)::vector\n",
    "# #         LIMIT :top_k;\n",
    "# #     \"\"\")\n",
    "# sql_query_cosine = text(\"\"\"\n",
    "#     SELECT id, ticket_id, text,\n",
    "#            embedding <=> (:query_embedding)::vector as distance\n",
    "#     FROM tickets\n",
    "#     ORDER BY distance ASC \n",
    "#     LIMIT :top_k;\n",
    "#     \"\"\")\n",
    "# top_k=3\n",
    "# result = session.execute(sql_query_cosine,{\"query_embedding\": query_embedding.tolist(), \"top_k\": top_k})\n",
    "# session.rollback()\n",
    "# result2=session.execute(sql_query_cosine,{\"query_embedding\": query_, \"top_k\": top_k})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3a685996",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "def query_similar_from_pgvector(query: str, top_k: int = 3):\n",
    "    query_embedding = np.array(get_vertex_embedding([query])[0], dtype=np.float32)\n",
    "\n",
    "    session.rollback() \n",
    "    # sql = text(\"\"\"\n",
    "    #        SELECT id, ticket_id, text,\n",
    "    #                embedding <-> (:query_embedding)::vector AS distance\n",
    "    #         FROM tickets\n",
    "    #         ORDER BY embedding <-> (:query_embedding)::vector\n",
    "    #         LIMIT :top_k;\n",
    "    #     \"\"\")\n",
    "    sql_query_cosine = text(\"\"\"\n",
    "    SELECT id, ticket_id, text,\n",
    "           embedding <=> (:query_embedding)::vector as distance\n",
    "    FROM tickets\n",
    "    ORDER BY distance ASC \n",
    "    LIMIT :top_k;\n",
    "    \"\"\")\n",
    "    print(\"Executinf seacrh query\")\n",
    "    result = session.execute(sql_query_cosine,{\"query_embedding\": query_embedding.tolist(), \"top_k\": top_k})\n",
    "\n",
    "    print(\"Search Results:\")\n",
    "    for row in result:\n",
    "        print(f\"ID: {row.id}, Ticket ID: {row.ticket_id}, Text: {row.text}, Distance: {row.distance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "63c6c03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating\n",
      "generated embedding for 100 ticketsa\n",
      "Kmeans cluster ids [0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 1 1\n",
      " 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1\n",
      " 1 0 0 1 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0 1 1 1 0 0 1 1]\n",
      "Inserted 100 tickets into PostgreSQL with pgvector.\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init='auto')\n",
    "process_and_store_to_pgvector(tickets_df=incidents_df, kmeans=kmeans)\n",
    "# process_and_store_to_pgvector(tickets=sample_tickets, kmeans=kmeans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5f192445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Query Examples ---\n",
      "Executinf seacrh query\n",
      "Search Results:\n",
      "ID: 323, Ticket ID: 1, Text: Cannot connect to the company VPN, it keeps saying authentication failed., Distance: 0.1441\n",
      "ID: 260, Ticket ID: INC-1037, Text: Resolved: User authentication failure after checking firewall rules., Distance: 0.3381\n",
      "ID: 241, Ticket ID: INC-1018, Text: Troubleshooting User authentication failure. Root cause unknown., Distance: 0.3419\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Query Examples ---\")\n",
    "query_similar_from_pgvector(\"vpn authentication failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e4090478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executinf seacrh query\n",
      "Search Results:\n",
      "ID: 242, Ticket ID: INC-1019, Text: Frequent reports of Storage capacity alert for users in AMER., Distance: 0.4306\n",
      "ID: 314, Ticket ID: INC-1091, Text: Frequent reports of Storage capacity alert for users in EMEA., Distance: 0.4380\n",
      "ID: 277, Ticket ID: INC-1054, Text: Frequent reports of Storage capacity alert for users in APAC., Distance: 0.4436\n"
     ]
    }
   ],
   "source": [
    "query_similar_from_pgvector(\"Storage capacity above 90%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2502811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langGraph_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
